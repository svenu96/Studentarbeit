{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bJb5wuuOfUYQ"
      },
      "outputs": [],
      "source": [
        "#importing libraries required for the project\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.cluster import KMeans\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reading and processing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv('./OCDetect_Export/OCDetect_Export/OCDetect_03_recording_06_c076109d-651c-46c4-a745-5df8b383bec3.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2661186 entries, 0 to 2661185\n",
            "Data columns (total 14 columns):\n",
            " #   Column       Dtype  \n",
            "---  ------       -----  \n",
            " 0   timestamp    float64\n",
            " 1   datetime     object \n",
            " 2   acc x        float64\n",
            " 3   acc y        float64\n",
            " 4   acc z        float64\n",
            " 5   gyro x       float64\n",
            " 6   gyro y       float64\n",
            " 7   gyro z       float64\n",
            " 8   user yes/no  float64\n",
            " 9   compulsive   float64\n",
            " 10  urge         float64\n",
            " 11  tense        float64\n",
            " 12  ignore       int64  \n",
            " 13  relabeled    int64  \n",
            "dtypes: float64(11), int64(2), object(1)\n",
            "memory usage: 284.2+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyqlbtKKtbyK",
        "outputId": "66033099-0106-4085-cbf9-4b7da2dc8578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2626968\n",
            "22812\n",
            "11406\n"
          ]
        }
      ],
      "source": [
        "label_counts = data['relabeled'].value_counts()\n",
        "count_label_0 = label_counts.get(0, 0)  # Count of label 0, default to 0 if not found\n",
        "count_label_1 = label_counts.get(1, 0)  # Count of label 1, default to 0 if not found\n",
        "count_label_2 = label_counts.get(2, 0)  # Count of label 2, default to 0 if not found\n",
        "if(count_label_0 & count_label_1 & count_label_2):\n",
        "    print(count_label_0)\n",
        "    print(count_label_1)\n",
        "    print(count_label_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqB3Hiu3zJWS",
        "outputId": "15800fc9-83fa-4a54-a15b-4a96b3045646"
      },
      "outputs": [],
      "source": [
        "filtered_data = data[(data['ignore'] == 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [timestamp, datetime, acc x, acc y, acc z, gyro x, gyro y, gyro z, user yes/no, compulsive, urge, tense, ignore, relabeled]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# Check for duplicate rows\n",
        "duplicate_rows = filtered_data[filtered_data.duplicated()]\n",
        "\n",
        "# Print or inspect duplicate rows\n",
        "print(duplicate_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   start_time  end_time  duration_seconds\n",
            "0      396.08    434.08              38.0\n",
            "1     4781.14   4819.14              38.0\n",
            "2     7948.52   7986.52              38.0\n",
            "3    35680.76  35718.76              38.0\n",
            "4    46789.64  46827.64              38.0\n",
            "5    48409.62  48447.62              38.0\n"
          ]
        }
      ],
      "source": [
        "# Convert 'timestamp_column' to datetime if it's not already\n",
        "#filtered_data['datetime'] = pd.to_datetime(your_data['timestamp_column'], errors='coerce')\n",
        "\n",
        "# Find the start indices where 'relabeled' changes to 2\n",
        "start_indices = filtered_data.index[(filtered_data['relabeled'] == 2) & (filtered_data['relabeled'].shift(1).isin([1, 0]))]\n",
        "\n",
        "# Find the end indices where 'relabeled' is 2\n",
        "end_indices = filtered_data.index[(filtered_data['relabeled'] == 2) & (~filtered_data['relabeled'].shift(-1).isin([2]))]\n",
        "\n",
        "# Create intervals based on the start and end indices\n",
        "intervals = []\n",
        "for start_idx, end_idx in zip(start_indices, end_indices):\n",
        "    interval_data = filtered_data.loc[start_idx:end_idx]\n",
        "    \n",
        "    # Calculate the duration of occurrences where 'relabeled' == 2 in each interval\n",
        "    duration_seconds = (interval_data['timestamp'].max() - interval_data['timestamp'].min())\n",
        "    \n",
        "    intervals.append({'start_time': interval_data['timestamp'].min(), 'end_time': interval_data['timestamp'].max(), 'duration_seconds': duration_seconds})\n",
        "\n",
        "# Convert the list of intervals to a DataFrame\n",
        "intervals_df = pd.DataFrame(intervals) / 10**9\n",
        "print(intervals_df)\n",
        "#print(intervals_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    start_time  end_time  duration_seconds\n",
            "0        36.44     74.44             38.00\n",
            "1      9028.46   9066.46             38.00\n",
            "2     14724.60  14762.60             38.00\n",
            "3     18458.00  18496.00             38.00\n",
            "4     32503.94  32541.94             38.00\n",
            "5     32850.02  32884.74             34.72\n",
            "6     36539.90  36577.90             38.00\n",
            "7     39896.54  39934.54             38.00\n",
            "8     44751.48  44789.48             38.00\n",
            "9     48679.26  48717.26             38.00\n",
            "10    49247.18  49285.18             38.00\n",
            "11    53063.36  53101.36             38.00\n"
          ]
        }
      ],
      "source": [
        "# Convert 'timestamp_column' to datetime if it's not already\n",
        "#filtered_data['datetime'] = pd.to_datetime(your_data['timestamp_column'], errors='coerce')\n",
        "\n",
        "# Find the start indices where 'relabeled' changes to 2\n",
        "start_indices = filtered_data.index[(filtered_data['relabeled'] == 1) & (filtered_data['relabeled'].shift(1).isin([2, 0]))]\n",
        "\n",
        "# Find the end indices where 'relabeled' is 2\n",
        "end_indices = filtered_data.index[(filtered_data['relabeled'] == 1) & (~filtered_data['relabeled'].shift(-1).isin([1]))]\n",
        "\n",
        "# Create intervals based on the start and end indices\n",
        "intervals = []\n",
        "for start_idx, end_idx in zip(start_indices, end_indices):\n",
        "    interval_data = filtered_data.loc[start_idx:end_idx]\n",
        "    \n",
        "    # Calculate the duration of occurrences where 'relabeled' == 2 in each interval\n",
        "    duration_seconds = (interval_data['timestamp'].max() - interval_data['timestamp'].min())\n",
        "    \n",
        "    intervals.append({'start_time': interval_data['timestamp'].min(), 'end_time': interval_data['timestamp'].max(), 'duration_seconds': duration_seconds})\n",
        "\n",
        "# Convert the list of intervals to a DataFrame\n",
        "intervals_df = pd.DataFrame(intervals) / 10**9\n",
        "print(intervals_df)\n",
        "#print(intervals_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    start_time  end_time  duration_seconds\n",
            "0         0.02     36.42             36.40\n",
            "1         0.04    396.06            396.02\n",
            "2         0.06   4781.12           4781.06\n",
            "3         0.08   7948.50           7948.42\n",
            "4         0.10   9028.44           9028.34\n",
            "5         0.12  14724.58          14724.46\n",
            "6         0.14  18457.98          18457.84\n",
            "7         0.16  32503.92          32503.76\n",
            "8         0.18  32839.98          32839.80\n",
            "9         0.20  35680.74          35680.54\n",
            "10        0.22  36539.88          36539.66\n",
            "11        0.24  39896.52          39896.28\n",
            "12        0.26  44751.46          44751.20\n",
            "13        0.28  46789.62          46789.34\n",
            "14        0.30  48409.60          48409.30\n",
            "15        0.32  48679.24          48678.92\n",
            "16        0.34  49247.16          49246.82\n",
            "17        0.36  53063.34          53062.98\n",
            "18        0.38  53223.70          53223.32\n"
          ]
        }
      ],
      "source": [
        "# Convert 'timestamp_column' to datetime if it's not already\n",
        "#filtered_data['datetime'] = pd.to_datetime(your_data['timestamp_column'], errors='coerce')\n",
        "\n",
        "# Find the start indices where 'relabeled' changes to 2\n",
        "start_indices = filtered_data.index[(filtered_data['relabeled'] == 0) & (filtered_data['relabeled'].shift(1).isin([2, 0]))]\n",
        "\n",
        "# Find the end indices where 'relabeled' is 2\n",
        "end_indices = filtered_data.index[(filtered_data['relabeled'] == 0) & (~filtered_data['relabeled'].shift(-1).isin([0]))]\n",
        "\n",
        "# Create intervals based on the start and end indices\n",
        "intervals = []\n",
        "for start_idx, end_idx in zip(start_indices, end_indices):\n",
        "    interval_data = filtered_data.loc[start_idx:end_idx]\n",
        "    \n",
        "    # Calculate the duration of occurrences where 'relabeled' == 2 in each interval\n",
        "    duration_seconds = (interval_data['timestamp'].max() - interval_data['timestamp'].min())\n",
        "    \n",
        "    intervals.append({'start_time': interval_data['timestamp'].min(), 'end_time': interval_data['timestamp'].max(), 'duration_seconds': duration_seconds})\n",
        "\n",
        "# Convert the list of intervals to a DataFrame\n",
        "intervals_df = pd.DataFrame(intervals) / 10**9\n",
        "print(intervals_df)\n",
        "#print(intervals_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_a=filtered_data[filtered_data[\"relabeled\"]==0][:11000]\n",
        "data_b=filtered_data[filtered_data[\"relabeled\"]==1][:11000]\n",
        "data_c=filtered_data[filtered_data[\"relabeled\"]==2][:11000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=pd.concat([data_a,data_b,data_c],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler=MinMaxScaler()\n",
        "data[[\"acc x\",\"acc y\",\"acc z\",\"gyro x\",\"gyro y\",\"gyro z\"]]=scaler.fit_transform(data[[\"acc x\",\"acc y\",\"acc z\",\"gyro x\",\"gyro y\",\"gyro z\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_data=data.drop(['timestamp','datetime','user yes/no','compulsive', 'urge', 'tense', 'ignore'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = new_data.drop(['relabeled'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AhgANLf62YGZ"
      },
      "outputs": [],
      "source": [
        "# choosing relabeled as label value\n",
        "label = new_data['relabeled']  # Create a 'label' column for majority voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of train DataFrames: 19800\n",
            "Number of test DataFrames: 13200\n"
          ]
        }
      ],
      "source": [
        "# Split data into train and test sets\n",
        "train_data, test_data, y_train, y_test = train_test_split(features, label, random_state=8, test_size=0.4, stratify=label)\n",
        "print(f\"Number of train DataFrames: {len(y_train)}\")\n",
        "print(f\"Number of test DataFrames: {len(y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6600\n",
            "6600\n",
            "6600\n"
          ]
        }
      ],
      "source": [
        "label_counts = y_train.value_counts()\n",
        "count_label_0 = label_counts.get(0, 0)  # Count of label 0, default to 0 if not found\n",
        "count_label_1 = label_counts.get(1, 0)  # Count of label 1, default to 0 if not found\n",
        "count_label_2 = label_counts.get(2, 0)  # Count of label 2, default to 0 if not found\n",
        "if(count_label_0 & count_label_1 & count_label_2):\n",
        "    print(count_label_0)\n",
        "    print(count_label_1)\n",
        "    print(count_label_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating sliding windows and majority voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hD-xyaYU2xQa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19751\n"
          ]
        }
      ],
      "source": [
        "# Define window size\n",
        "window_size = 50\n",
        "stride = 10\n",
        "train_data_val = train_data.values\n",
        "\n",
        "num_windows = (len(train_data) - window_size + 1)\n",
        "# Initialize lists to store windowed data and labels\n",
        "train_windows = []\n",
        "train_labels = []\n",
        "print(num_windows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(0, num_windows, stride):\n",
        "    window = train_data_val[i:i+window_size]  # Select only sensor axes columns\n",
        "    label_window = y_train.iloc[i:i+window_size]  # Select the label column for majority voting\n",
        "    majority_label = np.bincount(label_window).argmax()  # Majority voting\n",
        "    train_windows.append(window)  # Convert window to numpy array\n",
        "    train_labels.append(majority_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.6081053  0.47699533 0.58865512 ... 0.43383188 0.52902211 0.3251766 ]\n",
            " [0.52172102 0.50587105 0.69188526 ... 0.41825351 0.46609407 0.30285654]\n",
            " [0.64725728 0.49212779 0.72617945 ... 0.38544478 0.5517009  0.26323333]\n",
            " ...\n",
            " [0.66441752 0.47701186 0.68898879 ... 0.42134431 0.50589423 0.29144055]\n",
            " [0.61581074 0.46781661 0.68824729 ... 0.42649565 0.6021107  0.4473226 ]\n",
            " [0.67637136 0.49340124 0.60686811 ... 0.38388161 0.53227798 0.31611548]]\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_windows = np.array(train_windows)\n",
        "train_labels = np.array(train_labels)\n",
        "# Flatten the sensor axes data in each window\n",
        "num_trainsamp, num_fea_trainsamp = train_windows.shape[0], np.prod(train_windows.shape[1:])\n",
        "train_windows_reshaped = train_windows.reshape(num_trainsamp, num_fea_trainsamp)\n",
        "print(train_windows_reshaped)\n",
        "print(len(np.unique(train_labels)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1976, 300)\n",
            "(1976,)\n"
          ]
        }
      ],
      "source": [
        "print(train_windows_reshaped.shape)\n",
        "print(train_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate windows and labels using a sliding window approach\n",
        "window = []\n",
        "label_window = []\n",
        "test_windows = []\n",
        "test_labels = []\n",
        "for i in range(0,len(test_data)-window_size+1,stride):\n",
        "    window = test_data.iloc[i:i+window_size]  # Select only sensor axes columns\n",
        "    test_windows.append(window)\n",
        "    label_window = y_test.iloc[i:i+window_size]  # Select the label column for majority voting\n",
        "    majority_label = np.bincount(label_window).argmax()  # Majority voting\n",
        "    test_labels.append(majority_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.57345162 0.47601956 0.61412087 ... 0.41086399 0.39014258 0.26220947]\n",
            " [0.57540922 0.47418382 0.61569655 ... 0.42267656 0.55776355 0.31002354]\n",
            " [0.55420884 0.46935466 0.65107981 ... 0.38706124 0.57589536 0.22678406]\n",
            " ...\n",
            " [0.62305802 0.48405714 0.59655668 ... 0.45431291 0.6370832  0.31934062]\n",
            " [0.57153568 0.50403531 0.66361572 ... 0.43640755 0.53620747 0.31329987]\n",
            " [0.53829814 0.53884826 0.73725554 ... 0.43988915 0.50432244 0.22581139]]\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "test_windows = np.array(test_windows)\n",
        "test_labels = np.array(test_labels)\n",
        "# Flatten the sensor axes data in each window\n",
        "num_trainsamp, num_fea_trainsamp = test_windows.shape[0], np.prod(test_windows.shape[1:])\n",
        "test_windows_reshaped = test_windows.reshape(num_trainsamp, num_fea_trainsamp)\n",
        "print(test_windows_reshaped)\n",
        "print(len(np.unique(test_labels)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=9,\n",
              "                       min_samples_split=12, n_estimators=10, random_state=6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=9,\n",
              "                       min_samples_split=12, n_estimators=10, random_state=6)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', max_depth=9,\n",
              "                       min_samples_split=12, n_estimators=10, random_state=6)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf = RandomForestClassifier(n_estimators=10,max_depth=9, random_state=6, class_weight='balanced',min_samples_split=12)\n",
        "clf.fit(train_windows_reshaped, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3366261398176292\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.39      0.37       476\n",
            "           1       0.35      0.32      0.34       453\n",
            "           2       0.29      0.29      0.29       387\n",
            "\n",
            "    accuracy                           0.34      1316\n",
            "   macro avg       0.33      0.33      0.33      1316\n",
            "weighted avg       0.34      0.34      0.34      1316\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test set with SVM\n",
        "y_pred = clf.predict(test_windows_reshaped)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(test_labels, y_pred)\n",
        "print(accuracy)\n",
        "\n",
        "report = classification_report(test_labels, y_pred)\n",
        "# Print the report\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Naives Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Scores: [0.40060698 0.34446131 0.39513678]\n"
          ]
        }
      ],
      "source": [
        "# Create and train a Gaussian Naive Bayes classifier\n",
        "# Calculate class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights /= class_weights.sum()\n",
        "# Create a dictionary to map class labels to their corresponding weights\n",
        "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
        "NBclf = GaussianNB(priors=class_weights)\n",
        "NBclf.fit(train_windows_reshaped, train_labels)\n",
        "\n",
        "# Cross-validation\n",
        "cv_scores = cross_val_score(NBclf, train_windows_reshaped, train_labels, cv=3)\n",
        "print(\"Cross-Validation Scores:\", cv_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.3556\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.49      0.44       476\n",
            "           1       0.36      0.25      0.29       453\n",
            "           2       0.30      0.32      0.31       387\n",
            "\n",
            "    accuracy                           0.36      1316\n",
            "   macro avg       0.35      0.35      0.35      1316\n",
            "weighted avg       0.35      0.36      0.35      1316\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "y_pred = NBclf.predict(test_windows_reshaped)\n",
        "accuracy = accuracy_score(test_labels, y_pred)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "report = classification_report(test_labels, y_pred)\n",
        "# Print the report\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sruth\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lclf = LogisticRegression(random_state=42)\n",
        "lclf.fit(train_windows_reshaped, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3670212765957447\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.50      0.44       476\n",
            "           1       0.37      0.40      0.38       453\n",
            "           2       0.29      0.17      0.21       387\n",
            "\n",
            "    accuracy                           0.37      1316\n",
            "   macro avg       0.35      0.35      0.34      1316\n",
            "weighted avg       0.35      0.37      0.35      1316\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test set with logistic regression\n",
        "y_pred = lclf.predict(test_windows_reshaped)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(test_labels, y_pred)\n",
        "print(accuracy)\n",
        "\n",
        "report = classification_report(test_labels, y_pred)\n",
        "# Print the report\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost as xgb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "xgb_classifier = xgb.XGBClassifier()\n",
        "xgb_classifier.fit(train_windows_reshaped, train_labels)\n",
        "\n",
        "# Predictions\n",
        "xgb_predictions = xgb_classifier.predict(test_windows_reshaped)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3670212765957447\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.50      0.44       476\n",
            "           1       0.37      0.40      0.38       453\n",
            "           2       0.29      0.17      0.21       387\n",
            "\n",
            "    accuracy                           0.37      1316\n",
            "   macro avg       0.35      0.35      0.34      1316\n",
            "weighted avg       0.35      0.37      0.35      1316\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(test_labels, y_pred)\n",
        "print(accuracy)\n",
        "\n",
        "report = classification_report(test_labels, y_pred)\n",
        "# Print the report\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
